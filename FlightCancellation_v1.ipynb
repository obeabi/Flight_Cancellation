{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlightCancellation_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_XiUtgWGIOL4"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obeabi/Flight_Cancellation/blob/main/FlightCancellation_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW-CD9qPUXiR"
      },
      "source": [
        "# Written by Abiola Obembe\n",
        "# SDS Challenge #1 - Flight Cancellations\n",
        "## 2020-10-30\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaT4o-v0Up4V"
      },
      "source": [
        "## Problem Statement\n",
        "I have been hired by the US Department of Transportation (DOT) to analyze data from multiple airline carriers in the United States. The DOT wants to help airline carriers reduce the number of flight cancellations and improve travelers' experiences. My job is to help the DOT predict whether or not a flight will be canceled based on the data provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvyy8tV7VEZ5"
      },
      "source": [
        "### Step 1: Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsUbaYb6VCZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7d6273-6cc3-4d98-eaf9-320242f7695f"
      },
      "source": [
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "!pip install imbalanced-learn\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "print('Libraries installed successfully!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn) (0.17.0)\n",
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Libraries installed successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAN_VFooV8lb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "e4e0ec70-0154-4b58-c2b5-11d3884c05f4"
      },
      "source": [
        "# Importing the dataset and check the shape and total number of missing values\n",
        "\n",
        "df_train = pd.read_csv('public_flights.csv')\n",
        "\n",
        "df_train.head()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>FLIGHT_NUMBER</th>\n",
              "      <th>TAIL_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "      <th>CANCELLED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>AS</td>\n",
              "      <td>98</td>\n",
              "      <td>N407AS</td>\n",
              "      <td>ANC</td>\n",
              "      <td>SEA</td>\n",
              "      <td>5</td>\n",
              "      <td>205.0</td>\n",
              "      <td>1448</td>\n",
              "      <td>430</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>AA</td>\n",
              "      <td>2336</td>\n",
              "      <td>N3KUAA</td>\n",
              "      <td>LAX</td>\n",
              "      <td>PBI</td>\n",
              "      <td>10</td>\n",
              "      <td>280.0</td>\n",
              "      <td>2330</td>\n",
              "      <td>750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>US</td>\n",
              "      <td>840</td>\n",
              "      <td>N171US</td>\n",
              "      <td>SFO</td>\n",
              "      <td>CLT</td>\n",
              "      <td>20</td>\n",
              "      <td>286.0</td>\n",
              "      <td>2296</td>\n",
              "      <td>806</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>AA</td>\n",
              "      <td>258</td>\n",
              "      <td>N3HYAA</td>\n",
              "      <td>LAX</td>\n",
              "      <td>MIA</td>\n",
              "      <td>20</td>\n",
              "      <td>285.0</td>\n",
              "      <td>2342</td>\n",
              "      <td>805</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>AS</td>\n",
              "      <td>135</td>\n",
              "      <td>N527AS</td>\n",
              "      <td>SEA</td>\n",
              "      <td>ANC</td>\n",
              "      <td>25</td>\n",
              "      <td>235.0</td>\n",
              "      <td>1448</td>\n",
              "      <td>320</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH  DAY  ...  DISTANCE SCHEDULED_ARRIVAL  CANCELLED\n",
              "0  2015      1    1  ...      1448               430          0\n",
              "1  2015      1    1  ...      2330               750          0\n",
              "2  2015      1    1  ...      2296               806          0\n",
              "3  2015      1    1  ...      2342               805          0\n",
              "4  2015      1    1  ...      1448               320          0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B11R3A23b8os",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1eb3417-e53b-4465-98a6-133c32168a75"
      },
      "source": [
        "# print target column name as a list\n",
        "target_column = [df_train.columns[-1]]\n",
        "\n",
        "print(target_column)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CANCELLED']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW8EYUGAoUyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed67364-ca8f-4b4b-f378-7b4244eb3538"
      },
      "source": [
        "# Examine target column for unbalanced data\n",
        "df_train[target_column].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CANCELLED\n",
              "0            810176\n",
              "1             28682\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8P_OQlmKFLx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f62a9164-1bcc-41ee-b4d9-f47484c3fba5"
      },
      "source": [
        "count_classes = pd.value_counts(df_train['CANCELLED'], sort = True)\n",
        "count_classes.plot(kind = 'bar', rot = 0)\n",
        "plt.title(\"Cancelled Flights Distribution\")\n",
        "plt.xticks(range(2))\n",
        "plt.xlabel(\"CANCELLED\")\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7xVdZ3v8dc70VJTQSFSQLEkvWapeFK61aSZCPYDm1HDqZG8XqlRS+vWiE6P0at5R5spkzKKkoR+KVkmmUZk9muuKMcfaWjGCSUg1COg+CsN+8wf63N0ud1nn3107X3k8H4+Hvtx1vqs7699OO6P67u+ey1FBGZmZlV62UAPwMzMBh8nFzMzq5yTi5mZVc7JxczMKufkYmZmlXNyMTOzyjm52KAl6WxJ38rtsZJC0pAX0M4LqltbT9K1kqY1WfcXkv53f8daFUlLJR1cUVsfkPTT0n5I2qOKtrO9RyW9pqr2rBpOLlYZSf8oqTP/Y1+TH6ZvHehxtZqkeyU9ke+757VLbbmImBwRcyvor4pE2TPO+yVdLemwmrG+PiJ+UcU4IuLbETGxv2Ptpc/nJd2IeGVELK+ifauOk4tVQtIngC8A/w8YCewKfBmYMpDjaqP35Idcz+vPAz2gPgyNiFcC+wKLgCslfajqTl5IArTBwcnFXjRJOwDnACdHxA8i4rGI+GtE/CgiPpVlDpR0g6SH8qzmS5K2KrURkj4iaVmWuViSSsdPlHSXpEck3SlpfMZ3kfR9Sd2S7pH0sWbHLOmSHMtqSZ+RtEUe20LSf0p6UNJy4F0V/Z6e+b/u7ONz2cc9kk6pcxawm6T/yvf8U0nDM/6r/PlQnn28WdIekn4p6eFs8/JmxhQR90XERcDZwAWSXpbju1fSO3P7wDwj3ZBnOp9vMI4P5ZgvlLQWODtjv6np+ghJy3Os/1Hq95mpzNx/5uxI0nnA24AvZX9fyjLPTLPlv+u8/HtYIenTpbY/JOk3+W+7Pn/vk5v5PVn/OblYFd4MvAK4skGZp4GPA8Oz/KHASTVl3g28CXgjcAxwOICkoyk+/I4DtgfeC6zND40fAb8FRmWbp0k6vIkxXwpsBPYA9gcmAj3TLSfmWPYHOoCjmmivv04EJgP7AeOBI+uU+UfgeOBVwFbAJzP+d/lzaJ4l3QCcC/wUGAaMBr7Yz/H8IPvZs86xi4CLImJ74LXA/AbjADgIWE5xBnteL/29j+J3O57i7PZ/9TXAiPhX4NfAKdnfKXWKfRHYAXgN8HaKv5njS8cPAu6m+Dv8LHBJ+X9irDpOLlaFnYAHI2JjbwUi4uaIWBwRGyPiXuCrFP/xl50fEQ9FxJ+A6yk+eKH40P9sRCyJQldErKBIRCMi4pyIeCrn3b8GTG00WEkjgSOA0/Is6wHgwlK9Y4AvRMTKiFgH/HsTv4Mf5hnXQ5J+2ET5Yyg+sFdFxHrg/DplvhERf4iIJyg+0PerU6bHX4HdgF0i4i8RUXum0Jeeabwde2l7D0nDI+LRiFjcV1sR8cX8t36ilzIXRMS6/Lf+AnBsP8f7PHnmORU4IyIeyb+zzwH/VCq2IiK+FhFPA3OBnSmSoFXMycWqsBYY3mh+XdLr8sLxfZI2UFybGV5T7L7S9uPAK3N7DPDHOs3uBuxS+lB/CDiTvj8sdgO2BNaU6n2V4v/cAXYBVpbKr+ijPYAjI2JovuqdhdSq7WNlnTK9/T7q+RdAwE0qVnr1eSZQY1T+XFfn2AnA64DfS1oi6d19tFXvvTQqs4Li9/FiDaf4dy3/e63g2fcGpd9pRDyem41+r/YCOblYFW4AnqT+1E6PWcDvgXE5vXImxYdhM1ZSTMfUi99T+lAfGhHbRcQRTbT3JDC8VG/7iHh9Hl9DkdB67NrkOPtjDcX0VY8xvRWs43m3Ms9rJydGxC7Ah4Evq3/Lfd8HPEAxZVTb9rKIOJYi+V4AXCFp23rj6G18ddT+fnvOnB4Dtikde3U/2n6QZ8/gym2vbmI8VjEnF3vRIuJh4N+AiyUdKWkbSVtKmizps1lsO2AD8KikvYB/7kcXXwc+KekAFfaQtBtwE/CIpNMlbZ0XyfeR9KY+xruG4vrE5yRtL+llkl4rqWeabj7wMUmjJQ0DZvRjrM2aD5wqaZSkocDp/ajbDfyN4roCUFyXktSTrNZTfAj/ra+GJI2UdApwFsV00vPqSPqgpBF57KEM/63eOPrhU5KGSRoDnAr0LEC4Dfg7SbuqWChyRk29+3vrL6e65gPnSdou/0Y+AXyrXnlrLScXq0REfI7iP+RPU3zorAROAXquP3yS4gL1IxTXRZpazZRtf4/iwvB3sv4PgR3zw+TdFNci7qH4P9evU1zQ7ctxFBfJ76T4ML6CYv6dHN9CioUCt1Bc7K7a1ygS3O3ArcA1FAsMnu6rYk7nnAf8V07rTaC4/nSjpEeBBcCpfXz34yFJjwF3UFx/Ojoi5vRSdhKwNNu+CJgaEU/0Mo5mXQXcTJFMfgxcku9tEcXfxu15/OqaehcBR+Vqr5l12v0oxdnPcuA3FH8zvb0vayH5YWFmAy+XxH4lInbrs7DZJsBnLmYDIKfxjsjvb4yimJZqtJTbbJPiMxezASBpG+CXwF7AExRTQ6dGxIYBHZhZRZxczMyscp4WMzOzyvmmcmn48OExduzYgR6Gmdkm5eabb34wIkbUxp1c0tixY+ns7BzoYZiZbVIk1b2DhafFzMysck4uZmZWOScXMzOrnJOLmZlVzsnFzMwq5+RiZmaVc3IxM7PKObmYmVnlWppcJH08H7n6O0nflfQKSbtLulFSl6TLJW2VZV+e+115fGypnTMyfrekw0vxSRnrkjSjFK/bh5mZtUfLvqGftxH/GLB3RDwhaT4wleLBRBdGxGWSvkLxfO5Z+XN9ROwhaSrF41TfL2nvrPd6iuds/0zS67Kbi4HDgFXAEkkLIuLOrFuvj03e2Bk/HughDBr3nv+ugR6C2aDV6mmxIcDWkoZQPBd7DfAOiqf+Aczl2eeuT8l98vihkpTxyyLiyYi4B+gCDsxXV0Qsj4ingMuAKVmntz7MzKwNWpZcImI18J/AnyiSysMUjy19KCI2ZrFVwKjcHkXxaFzy+MPATuV4TZ3e4js16OM5JE2X1Cmps7u7+4W/WTMze46WJRdJwyjOOnanmM7aluJZ3C8ZETE7IjoiomPEiOfd1NPMzF6gVk6LvRO4JyK6I+KvwA+AtwBDc5oMYDSwOrdXA2MA8vgOwNpyvKZOb/G1DfowM7M2aGVy+RMwQdI2eR3kUOBO4HrgqCwzDbgqtxfkPnn851E8JnMBMDVXk+0OjANuApYA43Jl2FYUF/0XZJ3e+jAzszZo5TWXGykuqt8C3JF9zQZOBz4hqYvi+sglWeUSYKeMfwKYke0sBeZTJKafACdHxNN5TeUUYCFwFzA/y9KgDzMzawMV/6NvHR0dsSk8LMxLkavjpchmL56kmyOiozbub+ibmVnlnFzMzKxyTi5mZlY5JxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHJOLmZmVjknFzMzq5yTi5mZVc7JxczMKufkYmZmlXNyMTOzyjm5mJlZ5VqWXCTtKem20muDpNMk7ShpkaRl+XNYlpekmZK6JN0uaXyprWlZfpmkaaX4AZLuyDozJSnjdfswM7P2aFlyiYi7I2K/iNgPOAB4HLgSmAFcFxHjgOtyH2AyMC5f04FZUCQK4CzgIOBA4KxSspgFnFiqNynjvfVhZmZt0K5psUOBP0bECmAKMDfjc4Ejc3sKMC8Ki4GhknYGDgcWRcS6iFgPLAIm5bHtI2JxRAQwr6aten2YmVkbtCu5TAW+m9sjI2JNbt8HjMztUcDKUp1VGWsUX1Un3qiP55A0XVKnpM7u7u5+vykzM6uv5clF0lbAe4Hv1R7LM45oZf+N+oiI2RHREREdI0aMaOUwzMw2K+04c5kM3BIR9+f+/TmlRf58IOOrgTGleqMz1ig+uk68UR9mZtYG7Ugux/LslBjAAqBnxdc04KpS/LhcNTYBeDinthYCEyUNywv5E4GFeWyDpAm5Suy4mrbq9WFmZm0wpJWNS9oWOAz4cCl8PjBf0gnACuCYjF8DHAF0UawsOx4gItZJOhdYkuXOiYh1uX0ScCmwNXBtvhr1YWZmbdDS5BIRjwE71cTWUqweqy0bwMm9tDMHmFMn3gnsUydetw8zM2sPf0PfzMwq5+RiZmaVc3IxM7PKObmYmVnlnFzMzKxyTi5mZlY5JxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHJOLmZmVjknFzMzq5yTi5mZVa6lyUXSUElXSPq9pLskvVnSjpIWSVqWP4dlWUmaKalL0u2SxpfamZbll0maVoofIOmOrDMzH3dMb32YmVl7tPrM5SLgJxGxF7AvcBcwA7guIsYB1+U+wGRgXL6mA7OgSBTAWcBBwIHAWaVkMQs4sVRvUsZ768PMzNqgZclF0g7A3wGXAETEUxHxEDAFmJvF5gJH5vYUYF4UFgNDJe0MHA4sioh1EbEeWARMymPbR8TifETyvJq26vVhZmZt0Mozl92BbuAbkm6V9HVJ2wIjI2JNlrkPGJnbo4CVpfqrMtYovqpOnAZ9PIek6ZI6JXV2d3e/kPdoZmZ1tDK5DAHGA7MiYn/gMWqmp/KMI1o4hoZ9RMTsiOiIiI4RI0a0chhmZpuVViaXVcCqiLgx96+gSDb355QW+fOBPL4aGFOqPzpjjeKj68Rp0IeZmbVBy5JLRNwHrJS0Z4YOBe4EFgA9K76mAVfl9gLguFw1NgF4OKe2FgITJQ3LC/kTgYV5bIOkCblK7Liatur1YWZmbTCkxe1/FPi2pK2A5cDxFAltvqQTgBXAMVn2GuAIoAt4PMsSEesknQssyXLnRMS63D4JuBTYGrg2XwDn99KHmZm1QUuTS0TcBnTUOXRonbIBnNxLO3OAOXXincA+deJr6/VhZmbt4W/om5lZ5ZxczMysck4uZmZWOScXMzOrnJOLmZlVzsnFzMwq5+RiZmaVc3IxM7PKObmYmVnlnFzMzKxyTi5mZlY5JxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o1lVwkvaHVAzEzs8Gj2TOXL0u6SdJJknZotnFJ90q6Q9JtkjoztqOkRZKW5c9hGZekmZK6JN0uaXypnWlZfpmkaaX4Adl+V9ZVoz7MzKw9mkouEfE24APAGOBmSd+RdFiTfRwSEftFRM/jjmcA10XEOOC63AeYDIzL13RgFhSJAjgLOAg4EDirlCxmASeW6k3qow8zM2uDpq+5RMQy4NPA6cDbgZmSfi/p7/vZ5xRgbm7PBY4sxedFYTEwVNLOwOHAoohYFxHrgUXApDy2fUQsjogA5tW0Va8PMzNrg2avubxR0oXAXcA7gPdExP/I7QsbVA3gp5JuljQ9YyMjYk1u3weMzO1RwMpS3VUZaxRfVSfeqI/a9zVdUqekzu7u7gZvw8zM+mNIk+W+CHwdODMinugJRsSfJX26Qb23RsRqSa8CFkn6fflgRISk6Peo+6FRHxExG5gN0NHR0dJxmJltTpqdFnsX8J2exCLpZZK2AYiIb/ZWKSJW588HgCsprpncn1Na5M8Hsvhqims6PUZnrFF8dJ04DfowM7M2aDa5/AzYurS/TcZ6JWlbSdv1bAMTgd8BC4CeFV/TgKtyewFwXK4amwA8nFNbC4GJkoblhfyJwMI8tkHShFwldlxNW/X6MDOzNmh2WuwVEfFoz05EPNpz5tLASODKXB08hOLM5yeSlgDzJZ0ArACOyfLXAEcAXcDjwPHZ1zpJ5wJLstw5EbEut08CLqVIfNfmC+D8XvowM7M2aDa5PCZpfETcAsX3S4AnGlWIiOXAvnXia4FD68QDOLmXtuYAc+rEO4F9mu3DzMzao9nkchrwPUl/BgS8Gnh/y0ZlZmabtKaSS0QskbQXsGeG7o6Iv7ZuWGZmtilr9swF4E3A2KwzXhIRMa8lozIzs01aU8lF0jeB1wK3AU9nuOdb8WZmZs/R7JlLB7B3XnQ3MzNrqNnvufyO4iK+mZlZn5o9cxkO3CnpJuDJnmBEvLclozIzs01as8nl7FYOwszMBpdmlyL/UtJuwLiI+Fl+O3+L1g7NzMw2Vc3ecv9E4ArgqxkaBfywVYMyM7NNW7MX9E8G3gJsgGceHPaqVg3KzMw2bc0mlycj4qmeHUlDKL7nYmZm9jzNJpdfSjoT2FrSYcD3gB+1blhmZrYpaza5zAC6gTuAD1PcHr/REyjNzGwz1uxqsb8BX8uXmZlZQ83eW+we6lxjiYjXVD4iMzPb5DU7LdZBcVfkNwFvA2YC32qmoqQtJN0q6erc313SjZK6JF0uaauMvzz3u/L42FIbZ2T8bkmHl+KTMtYlaUYpXrcPMzNrj6aSS0SsLb1WR8QXgHc12cepwF2l/QuACyNiD2A9cELGTwDWZ/zCLIekvYGpwOuBScCXM2FtAVwMTAb2Bo7Nso36MDOzNmj2S5TjS68OSR+hiSk1SaMpktDXc1/AOyi+kAkwFzgyt6fkPnn80Cw/BbgsIp6MiHuALuDAfHVFxPJcJn0ZMKWPPszMrA2avbfY50rbG4F7gWOaqPcF4F+A7XJ/J+ChiNiY+6sovu1P/lwJEBEbJT2c5UcBi0ttluusrIkf1EcfZmbWBs2uFjukvw1LejfwQETcLOng/tZvB0nTgekAu+666wCPxsxs8Gh2tdgnGh2PiM/XCb8FeK+kI4BXANsDFwFDJQ3JM4vRwOosvxoYA6zKOwDsAKwtxXuU69SLr23QR+24ZwOzATo6OnzHATOzivRntdg/U0wvjQI+AoynmO7arl6FiDgjIkZHxFiKC/I/j4gPANcDR2WxacBVub0g98njP88nXy4ApuZqst2BccBNwBJgXK4M2yr7WJB1euvDzMzaoNlrLqOB8RHxCICks4EfR8QHX0CfpwOXSfoMcCtwScYvAb4pqQtYR5EsiIilkuYDd1Jc7zk5Ip7OcZwCLKS4/f+ciFjaRx9mZtYGzSaXkcBTpf2nMtaUiPgF8IvcXk6x0qu2zF+Ao3upfx5wXp34NRS3oqmN1+3DzMzao9nkMg+4SdKVuX8kzy4bNjMze45mV4udJ+laim/nAxwfEbe2blhmZrYpa/aCPsA2wIaIuIhiRdfuLRqTmZlt4pr9hv5ZFBfJz8jQljR5bzEzM9v8NHvm8j7gvcBjABHxZ3pZgmxmZtZscnkqvz8SAJK2bd2QzMxsU9dscpkv6asU33w/EfgZfnCYmZn1opk7Gwu4HNgL2ADsCfxbRCxq8djMzGwT1WdyiYiQdE1EvAFwQjEzsz41Oy12i6Q3tXQkZmY2aDT7Df2DgA9KupdixZgoTmre2KqBmZnZpqthcpG0a0T8CTi8UTkzM7Oyvs5cfkhxN+QVkr4fEf/QjkGZmdmmra9rLiptv6aVAzEzs8Gjr+QSvWybmZn1qq9psX0lbaA4g9k6t+HZC/rbt3R0Zma2SWqYXCJii3YNxMzMBo/+3HK/XyS9QtJNkn4raamk/5vx3SXdKKlL0uWStsr4y3O/K4+PLbV1RsbvlnR4KT4pY12SZpTidfswM7P2aFlyAZ4E3hER+wL7AZMkTQAuAC6MiD2A9cAJWf4EYH3GL8xySNobmAq8HpgEfFnSFpK2AC4GJgN7A8dmWRr0YWZmbdCy5BKFR3N3y3wF8A7giozPpXhkMsAUnn108hXAoXlfsynAZRHxZETcA3QBB+arKyKWR8RTwGXAlKzTWx9mZtYGrTxzIc8wbgMeoLgv2R+BhyJiYxZZBYzK7VHASoA8/jCwUzleU6e3+E4N+qgd33RJnZI6u7u7X8xbNTOzkpYml4h4OiL2A0ZTnGns1cr++isiZkdER0R0jBgxYqCHY2Y2aLQ0ufSIiIeA64E3UzwTpmeV2mhgdW6vBsYA5PEdgLXleE2d3uJrG/RhZmZt0MrVYiMkDc3trYHDgLsoksxRWWwacFVuL8h98vjP8+mXC4CpuZpsd2AccBOwBBiXK8O2orjovyDr9NaHmZm1QbN3RX4hdgbm5qqulwHzI+JqSXcCl0n6DHArcEmWvwT4pqQuYB1FsiAilkqaD9wJbAROjoinASSdAiwEtgDmRMTSbOv0XvowM7M2aFlyiYjbgf3rxJdTXH+pjf8FOLqXts4DzqsTvwa4ptk+zMysPdpyzcXMzDYvTi5mZlY5JxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHJOLmZmVjknFzMzq5yTi5mZVc7JxczMKufkYmZmlXNyMTOzyjm5mJlZ5ZxczMysci1LLpLGSLpe0p2Slko6NeM7SlokaVn+HJZxSZopqUvS7ZLGl9qaluWXSZpWih8g6Y6sM1OSGvVhZmbt0cozl43A/4mIvYEJwMmS9gZmANdFxDjgutwHmAyMy9d0YBYUiQI4CziI4tHFZ5WSxSzgxFK9SRnvrQ8zM2uDliWXiFgTEbfk9iPAXcAoYAowN4vNBY7M7SnAvCgsBoZK2hk4HFgUEesiYj2wCJiUx7aPiMUREcC8mrbq9WFmZm3QlmsuksYC+wM3AiMjYk0eug8YmdujgJWlaqsy1ii+qk6cBn3Ujmu6pE5Jnd3d3f1/Y2ZmVlfLk4ukVwLfB06LiA3lY3nGEa3sv1EfETE7IjoiomPEiBGtHIaZ2WalpclF0pYUieXbEfGDDN+fU1rkzwcyvhoYU6o+OmON4qPrxBv1YWZmbdDK1WICLgHuiojPlw4tAHpWfE0DrirFj8tVYxOAh3NqayEwUdKwvJA/EViYxzZImpB9HVfTVr0+zMysDYa0sO23AP8E3CHptoydCZwPzJd0ArACOCaPXQMcAXQBjwPHA0TEOknnAkuy3DkRsS63TwIuBbYGrs0XDfowM7M2aFlyiYjfAOrl8KF1ygdwci9tzQHm1Il3AvvUia+t14eZmbWHv6FvZmaVc3IxM7PKObmYmVnlnFzMzKxyTi5mZlY5JxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHJOLmZmVjknFzMzq5yTi5mZVc7JxczMKtfKxxzPkfSApN+VYjtKWiRpWf4clnFJmimpS9LtksaX6kzL8sskTSvFD5B0R9aZmY867rUPMzNrn1aeuVwKTKqJzQCui4hxwHW5DzAZGJev6cAsKBIFcBZwEHAgcFYpWcwCTizVm9RHH2Zm1iYtSy4R8StgXU14CjA3t+cCR5bi86KwGBgqaWfgcGBRRKyLiPXAImBSHts+Ihbn45Hn1bRVrw8zM2uTdl9zGRkRa3L7PmBkbo8CVpbKrcpYo/iqOvFGfTyPpOmSOiV1dnd3v4C3Y2Zm9QzYBf0844iB7CMiZkdER0R0jBgxopVDMTPbrLQ7udyfU1rkzwcyvhoYUyo3OmON4qPrxBv1YWZmbdLu5LIA6FnxNQ24qhQ/LleNTQAezqmthcBEScPyQv5EYGEe2yBpQq4SO66mrXp9mJlZmwxpVcOSvgscDAyXtIpi1df5wHxJJwArgGOy+DXAEUAX8DhwPEBErJN0LrAky50TET2LBE6iWJG2NXBtvmjQh5mZtUnLkktEHNvLoUPrlA3g5F7amQPMqRPvBPapE19brw8zM2sff0PfzMwq5+RiZmaVc3IxM7PKObmYmVnlnFzMzKxyTi5mZlY5JxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeVaduNKM9u8jJ3x44EewqBy7/nvGughvCg+czEzs8o5uZiZWeWcXMzMrHJOLmZmVrlBm1wkTZJ0t6QuSTMGejxmZpuTQZlcJG0BXAxMBvYGjpW098COysxs8zEokwtwINAVEcsj4ingMmDKAI/JzGyzMVi/5zIKWFnaXwUcVFtI0nRgeu4+KunuNoxtczEceHCgB9GILhjoEdgAecn/bcIm9fe5W73gYE0uTYmI2cDsgR7HYCSpMyI6BnocZrX8t9keg3VabDUwprQ/OmNmZtYGgzW5LAHGSdpd0lbAVGDBAI/JzGyzMSinxSJio6RTgIXAFsCciFg6wMPa3Hi60V6q/LfZBoqIgR6DmZkNMoN1WszMzAaQk4uZmVXOycUq5dvu2EuVpDmSHpD0u4Eey+bAycUq49vu2EvcpcCkgR7E5sLJxark2+7YS1ZE/ApYN9Dj2Fw4uViV6t12Z9QAjcXMBpCTi5mZVc7Jxark2+6YGeDkYtXybXfMDHBysQpFxEag57Y7dwHzfdsde6mQ9F3gBmBPSasknTDQYxrMfPsXMzOrnM9czMysck4uZmZWOScXMzOrnJOLmZlVzsnFzMwq5+Ri1k+SXi3pMkl/lHSzpGskvS6PnSbpL5J2KJU/WFJIek8pdrWkg3N7S0nnS1om6RZJN0ianMfulXSHpNvyNTPjl0o6qmZcY+vd8TfL3lNq4/9n/EOSuiXdmn0vlPQ/W/Ars83QoHzMsVmrSBJwJTA3IqZmbF9gJPAH4FiKL5P+PfCNUtVVwL8CP6rT7LnAzsA+EfGkpJHA20vHD4mIB1/k0D8VEVfUiV8eEafk+zgE+IGkQyLirhfZn23mfOZi1j+HAH+NiK/0BCLitxHxa0mvBV4JfJoiyZT9FnhY0mHloKRtgBOBj0bEk9ne/RExv5Vvop6IuJ7i+fLT2923DT5OLmb9sw9wcy/HplI8ZuDXFN8CH1lz/DyKxFO2B/CniNjQoM/rS1NaH38hgwb+o9TGtxuUuwXY6wX2YfYMT4uZVedY4H0R8TdJ3weOBr7UczAifiUJSW/tZ7utnBarpRfZjxng5GLWX0uBo2qDkt4AjAMWFZdl2Aq4h1JyST1nLxtzvwvYVdL2fZy9tMv+FPeFM3tRPC1m1j8/B14u6ZnrEpLeCMwEzo6IsfnaBdhF0m7lyhHxU2AY8Mbcfxy4BLgo7ySNpBGSjm7P23mWpLdTXG/5Wrv7tsHHycWsH6K40+v7gHfmUuSlwL8DB1OsIiu7kuI6TK3zeO5zbz4NdAN35lLiq2wzdQYAAABkSURBVIHyWUz5msu8UvyreXffVZJuyNiepdiqUpIqX3O5rSeRAe/P/T8AZwL/4JViVgXfFdnMzCrnMxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHL/DV3GLu9saU4fAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfjbSepuMJ0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba70c5ab-0f53-4448-a3db-b8b56d97b140"
      },
      "source": [
        "# gET THE CANCELLED AND NOT CANCEELED FLIFGTS\n",
        "Cancelled = df_train[df_train['CANCELLED']== 1]\n",
        "notCancelled = df_train[df_train['CANCELLED']== 0]\n",
        "\n",
        "print(Cancelled.shape, notCancelled.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28682, 14) (810176, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy0G7oUKh0wV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6dc1d0-8293-4c03-e118-640d96b49b3c"
      },
      "source": [
        "# Importing the train-set nd check the shape and total number of missing values\n",
        "\n",
        "print(\"The shape of the train-set is:\", (df_train.shape))\n",
        "print(\"The number of rows in the train-set is:\", str(df_train.shape[0]))\n",
        "print(\"The number of columns in the train-set is:\", str(df_train.shape[1]))\n",
        "\n",
        "missing_valuestrain = df_train.isnull().sum().sum()\n",
        "\n",
        "print(\"The number of missing values in the train-set is:\", str(missing_valuestrain))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the train-set is: (838858, 14)\n",
            "The number of rows in the train-set is: 838858\n",
            "The number of columns in the train-set is: 14\n",
            "The number of missing values in the train-set is: 5983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCbWRNp_n7RS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "fee124eb-510c-4ce5-a364-cdd49cde844f"
      },
      "source": [
        "# create dataframe for test test\n",
        "df_test = pd.read_csv('pred_flights.csv')\n",
        "df_test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2015</th>\n",
              "      <th>2</th>\n",
              "      <th>25</th>\n",
              "      <th>3</th>\n",
              "      <th>WN</th>\n",
              "      <th>1046</th>\n",
              "      <th>N731SA</th>\n",
              "      <th>LAS</th>\n",
              "      <th>PHX</th>\n",
              "      <th>700</th>\n",
              "      <th>65</th>\n",
              "      <th>255</th>\n",
              "      <th>905</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>2251</td>\n",
              "      <td>N279WN</td>\n",
              "      <td>LAS</td>\n",
              "      <td>RNO</td>\n",
              "      <td>700</td>\n",
              "      <td>80</td>\n",
              "      <td>345</td>\n",
              "      <td>820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>857</td>\n",
              "      <td>N277WN</td>\n",
              "      <td>LAS</td>\n",
              "      <td>SMF</td>\n",
              "      <td>700</td>\n",
              "      <td>90</td>\n",
              "      <td>397</td>\n",
              "      <td>830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>2864</td>\n",
              "      <td>N8632A</td>\n",
              "      <td>LAX</td>\n",
              "      <td>BWI</td>\n",
              "      <td>700</td>\n",
              "      <td>295</td>\n",
              "      <td>2329</td>\n",
              "      <td>1455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>3220</td>\n",
              "      <td>N8659D</td>\n",
              "      <td>LAX</td>\n",
              "      <td>PHX</td>\n",
              "      <td>700</td>\n",
              "      <td>80</td>\n",
              "      <td>370</td>\n",
              "      <td>920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>2954</td>\n",
              "      <td>N789SW</td>\n",
              "      <td>LGA</td>\n",
              "      <td>HOU</td>\n",
              "      <td>700</td>\n",
              "      <td>265</td>\n",
              "      <td>1428</td>\n",
              "      <td>1025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   2015  2  25  3  WN  1046  N731SA  LAS  PHX  700   65   255   905\n",
              "0  2015  2  25  3  WN  2251  N279WN  LAS  RNO  700   80   345   820\n",
              "1  2015  2  25  3  WN   857  N277WN  LAS  SMF  700   90   397   830\n",
              "2  2015  2  25  3  WN  2864  N8632A  LAX  BWI  700  295  2329  1455\n",
              "3  2015  2  25  3  WN  3220  N8659D  LAX  PHX  700   80   370   920\n",
              "4  2015  2  25  3  WN  2954  N789SW  LGA  HOU  700  265  1428  1025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYQNQY7on7s3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "89bcbf03-3a74-432f-ad6e-007d1729787d"
      },
      "source": [
        "# test set dataframe is missing headers information so we will re-initailize it, deleting the target column label\n",
        "labels = df_train.columns\n",
        "\n",
        "new_label= labels[:-1]  # select all column labels except the target column\n",
        "\n",
        "#new_label\n",
        "df_test = pd.read_csv('pred_flights.csv', header =None, names = new_label)\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>FLIGHT_NUMBER</th>\n",
              "      <th>TAIL_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>1046</td>\n",
              "      <td>N731SA</td>\n",
              "      <td>LAS</td>\n",
              "      <td>PHX</td>\n",
              "      <td>700</td>\n",
              "      <td>65</td>\n",
              "      <td>255</td>\n",
              "      <td>905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>2251</td>\n",
              "      <td>N279WN</td>\n",
              "      <td>LAS</td>\n",
              "      <td>RNO</td>\n",
              "      <td>700</td>\n",
              "      <td>80</td>\n",
              "      <td>345</td>\n",
              "      <td>820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>857</td>\n",
              "      <td>N277WN</td>\n",
              "      <td>LAS</td>\n",
              "      <td>SMF</td>\n",
              "      <td>700</td>\n",
              "      <td>90</td>\n",
              "      <td>397</td>\n",
              "      <td>830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>2864</td>\n",
              "      <td>N8632A</td>\n",
              "      <td>LAX</td>\n",
              "      <td>BWI</td>\n",
              "      <td>700</td>\n",
              "      <td>295</td>\n",
              "      <td>2329</td>\n",
              "      <td>1455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>WN</td>\n",
              "      <td>3220</td>\n",
              "      <td>N8659D</td>\n",
              "      <td>LAX</td>\n",
              "      <td>PHX</td>\n",
              "      <td>700</td>\n",
              "      <td>80</td>\n",
              "      <td>370</td>\n",
              "      <td>920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH  DAY  ...  SCHEDULED_TIME DISTANCE  SCHEDULED_ARRIVAL\n",
              "0  2015      2   25  ...              65      255                905\n",
              "1  2015      2   25  ...              80      345                820\n",
              "2  2015      2   25  ...              90      397                830\n",
              "3  2015      2   25  ...             295     2329               1455\n",
              "4  2015      2   25  ...              80      370                920\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dGjL3dCoEq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542599f5-903f-4032-d539-ff2776c554e3"
      },
      "source": [
        "# Importing the test-set and check the shape and total number of missing values\n",
        "\n",
        "print(\"The shape of the test-set is:\", (df_test.shape))\n",
        "print(\"The number of rows in the test-set is:\", str(df_test.shape[0]))\n",
        "print(\"The number of columns in the test-set is:\", str(df_test.shape[1]))\n",
        "\n",
        "missing_valuestest = df_test.isnull().sum().sum()\n",
        "\n",
        "print(\"The number of missing values in the test-set is:\", str(missing_valuestest))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the test-set is: (209717, 13)\n",
            "The number of rows in the test-set is: 209717\n",
            "The number of columns in the test-set is: 13\n",
            "The number of missing values in the test-set is: 1769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDQCCXw1oIWW"
      },
      "source": [
        "### Step 2: Feature Engineering (Training and Test Set )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EuLlcgtk9IV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903ccf27-668c-4c52-f601-a45695212119"
      },
      "source": [
        "# Examine the data types for train dataframe\n",
        "df_train.dtypes"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YEAR                     int64\n",
              "MONTH                    int64\n",
              "DAY                      int64\n",
              "DAY_OF_WEEK              int64\n",
              "AIRLINE                 object\n",
              "FLIGHT_NUMBER            int64\n",
              "TAIL_NUMBER             object\n",
              "ORIGIN_AIRPORT          object\n",
              "DESTINATION_AIRPORT     object\n",
              "SCHEDULED_DEPARTURE      int64\n",
              "SCHEDULED_TIME         float64\n",
              "DISTANCE                 int64\n",
              "SCHEDULED_ARRIVAL        int64\n",
              "CANCELLED                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veARPOxffHyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba834871-c673-41b4-d004-d5e8942bd012"
      },
      "source": [
        "# Check for training set data frame info\n",
        "df_train.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 838858 entries, 0 to 838857\n",
            "Data columns (total 14 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   YEAR                 838858 non-null  int64  \n",
            " 1   MONTH                838858 non-null  int64  \n",
            " 2   DAY                  838858 non-null  int64  \n",
            " 3   DAY_OF_WEEK          838858 non-null  int64  \n",
            " 4   AIRLINE              838858 non-null  object \n",
            " 5   FLIGHT_NUMBER        838858 non-null  int64  \n",
            " 6   TAIL_NUMBER          832877 non-null  object \n",
            " 7   ORIGIN_AIRPORT       838858 non-null  object \n",
            " 8   DESTINATION_AIRPORT  838858 non-null  object \n",
            " 9   SCHEDULED_DEPARTURE  838858 non-null  int64  \n",
            " 10  SCHEDULED_TIME       838856 non-null  float64\n",
            " 11  DISTANCE             838858 non-null  int64  \n",
            " 12  SCHEDULED_ARRIVAL    838858 non-null  int64  \n",
            " 13  CANCELLED            838858 non-null  int64  \n",
            "dtypes: float64(1), int64(9), object(4)\n",
            "memory usage: 89.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFcG975h-XS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81136e3-1378-4686-b8c8-3857962a73e0"
      },
      "source": [
        "# Dealing with missing values in the train-set\n",
        "\n",
        "df_train.isnull().sum()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YEAR                      0\n",
              "MONTH                     0\n",
              "DAY                       0\n",
              "DAY_OF_WEEK               0\n",
              "AIRLINE                   0\n",
              "FLIGHT_NUMBER             0\n",
              "TAIL_NUMBER            5981\n",
              "ORIGIN_AIRPORT            0\n",
              "DESTINATION_AIRPORT       0\n",
              "SCHEDULED_DEPARTURE       0\n",
              "SCHEDULED_TIME            2\n",
              "DISTANCE                  0\n",
              "SCHEDULED_ARRIVAL         0\n",
              "CANCELLED                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v47C0PRloUg1"
      },
      "source": [
        "#### (A) Dealing with Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbLaCRECJivv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "dff9e91b-50d1-4b63-d25c-4f751083cab7"
      },
      "source": [
        "# Remove rows with missing target, separate target from predictors\n",
        "X_full = df_train.copy()\n",
        "X_full.dropna(axis=0, subset=['CANCELLED'], inplace=True)\n",
        "y = X_full.CANCELLED\n",
        "X_full.drop(['CANCELLED'], axis=1, inplace=True)\n",
        "\n",
        "# Show X_full dataframe representing predictors only\n",
        "X_full.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>FLIGHT_NUMBER</th>\n",
              "      <th>TAIL_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>AS</td>\n",
              "      <td>98</td>\n",
              "      <td>N407AS</td>\n",
              "      <td>ANC</td>\n",
              "      <td>SEA</td>\n",
              "      <td>5</td>\n",
              "      <td>205.0</td>\n",
              "      <td>1448</td>\n",
              "      <td>430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>AA</td>\n",
              "      <td>2336</td>\n",
              "      <td>N3KUAA</td>\n",
              "      <td>LAX</td>\n",
              "      <td>PBI</td>\n",
              "      <td>10</td>\n",
              "      <td>280.0</td>\n",
              "      <td>2330</td>\n",
              "      <td>750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>US</td>\n",
              "      <td>840</td>\n",
              "      <td>N171US</td>\n",
              "      <td>SFO</td>\n",
              "      <td>CLT</td>\n",
              "      <td>20</td>\n",
              "      <td>286.0</td>\n",
              "      <td>2296</td>\n",
              "      <td>806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>AA</td>\n",
              "      <td>258</td>\n",
              "      <td>N3HYAA</td>\n",
              "      <td>LAX</td>\n",
              "      <td>MIA</td>\n",
              "      <td>20</td>\n",
              "      <td>285.0</td>\n",
              "      <td>2342</td>\n",
              "      <td>805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>AS</td>\n",
              "      <td>135</td>\n",
              "      <td>N527AS</td>\n",
              "      <td>SEA</td>\n",
              "      <td>ANC</td>\n",
              "      <td>25</td>\n",
              "      <td>235.0</td>\n",
              "      <td>1448</td>\n",
              "      <td>320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH  DAY  ...  SCHEDULED_TIME DISTANCE  SCHEDULED_ARRIVAL\n",
              "0  2015      1    1  ...           205.0     1448                430\n",
              "1  2015      1    1  ...           280.0     2330                750\n",
              "2  2015      1    1  ...           286.0     2296                806\n",
              "3  2015      1    1  ...           285.0     2342                805\n",
              "4  2015      1    1  ...           235.0     1448                320\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcl3pplmKY1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23113b1a-fdb4-4b8a-8f17-f65b7ad6fa7c"
      },
      "source": [
        "# Print first 10 entries of target column\n",
        "y[0:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "5    0\n",
              "6    0\n",
              "7    0\n",
              "8    0\n",
              "9    0\n",
              "Name: CANCELLED, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WtlGwLWKpHk"
      },
      "source": [
        "# Break off validation set from training data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y,train_size=0.8, test_size=0.2, random_state=0)\n",
        "\n",
        "# Organize test set\n",
        "X_test_full = df_test.copy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJkFXT9IL1O1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4055039d-5551-4047-807d-e80c0ffa1b47"
      },
      "source": [
        "# Select categorical columns from X_train_full\n",
        "# All categorical columns\n",
        "category_cols = [col for col in X_train_full.columns if X_train_full[col].dtype == \"object\"]\n",
        "category_cols"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AIRLINE', 'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RbfVEU1NzR0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "5d46f1af-7ce2-402a-fe65-4fceb6aac091"
      },
      "source": [
        "# Print object caregories for X_train_full for inspection\n",
        "X_train_full[category_cols].head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>TAIL_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>645400</th>\n",
              "      <td>HA</td>\n",
              "      <td>N370HA</td>\n",
              "      <td>HNL</td>\n",
              "      <td>PDX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546962</th>\n",
              "      <td>DL</td>\n",
              "      <td>N334NW</td>\n",
              "      <td>SAN</td>\n",
              "      <td>MSP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159193</th>\n",
              "      <td>EV</td>\n",
              "      <td>N14904</td>\n",
              "      <td>IAH</td>\n",
              "      <td>ATL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288445</th>\n",
              "      <td>DL</td>\n",
              "      <td>N553NW</td>\n",
              "      <td>MCO</td>\n",
              "      <td>ATL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298874</th>\n",
              "      <td>WN</td>\n",
              "      <td>N8312C</td>\n",
              "      <td>ALB</td>\n",
              "      <td>MCO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       AIRLINE TAIL_NUMBER ORIGIN_AIRPORT DESTINATION_AIRPORT\n",
              "645400      HA      N370HA            HNL                 PDX\n",
              "546962      DL      N334NW            SAN                 MSP\n",
              "159193      EV      N14904            IAH                 ATL\n",
              "288445      DL      N553NW            MCO                 ATL\n",
              "298874      WN      N8312C            ALB                 MCO"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9I3kH0uMH_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076be07f-4a83-419f-e8ab-19a518613c8e"
      },
      "source": [
        "# Let us see the cardanilatity of each column for the categorical columns in X_train_full and X_valid_full\n",
        "# Unique value sin each columns\n",
        "for cols in category_cols:\n",
        "    print(\"Unique values in\", cols,  \"column in training data:\", X_train_full[cols].nunique())\n",
        "    print(\"\\nUnique values in\" , cols,  \"column in validation data:\", X_valid_full[cols].nunique())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique values in AIRLINE column in training data: 14\n",
            "\n",
            "Unique values in AIRLINE column in validation data: 14\n",
            "Unique values in TAIL_NUMBER column in training data: 4470\n",
            "\n",
            "Unique values in TAIL_NUMBER column in validation data: 4372\n",
            "Unique values in ORIGIN_AIRPORT column in training data: 315\n",
            "\n",
            "Unique values in ORIGIN_AIRPORT column in validation data: 315\n",
            "Unique values in DESTINATION_AIRPORT column in training data: 315\n",
            "\n",
            "Unique values in DESTINATION_AIRPORT column in validation data: 315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMIsFnBAhNAt"
      },
      "source": [
        "##### We observe that the cardinality of the columns are all greater than 10 hence one-hot encoding will lead to a huge number of new columns and hence result in the curse of dimensionality problem. Hence in this project we proceed with label encoding for the baseline project. We hope to improve the categorical encoding columns with the category encoder library in the future using the count encoder, target encoder and catboost encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxH9EeOZO30A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38da647f-3fa5-4431-db61-f2825f8dc641"
      },
      "source": [
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "low_cardinality = [cname for cname in X_train_full.columns if\n",
        "                    X_train_full[cname].nunique() < 10 and\n",
        "                    X_train_full[cname].dtype == \"object\"]\n",
        "low_cardinality"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQAbj6bjhv5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efd89d6-03d7-4a3c-985b-4445397a8e8e"
      },
      "source": [
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "high_cardinality = [cname for cname in X_train_full.columns if\n",
        "                    X_train_full[cname].nunique() > 10 and\n",
        "                    X_train_full[cname].dtype == \"object\"]\n",
        "high_cardinality"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AIRLINE', 'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ye0bnr2NGMk"
      },
      "source": [
        "##### We observe that all columns have high cardinality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA_QbbKyPSAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c930d8e6-48d9-405e-dc2c-1c40922b4212"
      },
      "source": [
        "# Columns that can be safely label encoded in validation set\n",
        "good_label_cols = [col for col in category_cols if\n",
        "                   set(X_train_full[col]) == set(X_valid_full[col]) and \n",
        "                   set(X_train_full[col]) == set(X_test_full[col])]\n",
        "\n",
        "\n",
        "# Problematic columns that will be dropped from the validation dataset\n",
        "bad_label_cols = list(set(category_cols) - set(good_label_cols))\n",
        "\n",
        "print('Categorical columns that will be label encoded:', good_label_cols)\n",
        "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categorical columns that will be label encoded: ['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT']\n",
            "\n",
            "Categorical columns that will be dropped from the dataset: ['TAIL_NUMBER']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw06sULQPlAY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "b822e0a9-d00d-40b7-8ddf-0cb4cddec757"
      },
      "source": [
        "# Drop categorical columns that will not be encoded\n",
        "label_X_train = X_train_full.drop(bad_label_cols, axis=1)\n",
        "label_X_valid = X_valid_full.drop(bad_label_cols, axis=1)\n",
        "label_X_test = X_test_full.drop(bad_label_cols, axis=1)\n",
        "\n",
        "# print dataframe for inspection\n",
        "label_X_train.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>FLIGHT_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>645400</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>HA</td>\n",
              "      <td>26</td>\n",
              "      <td>HNL</td>\n",
              "      <td>PDX</td>\n",
              "      <td>1500</td>\n",
              "      <td>330.0</td>\n",
              "      <td>2603</td>\n",
              "      <td>2230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546962</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>DL</td>\n",
              "      <td>1864</td>\n",
              "      <td>SAN</td>\n",
              "      <td>MSP</td>\n",
              "      <td>625</td>\n",
              "      <td>227.0</td>\n",
              "      <td>1532</td>\n",
              "      <td>1212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159193</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>EV</td>\n",
              "      <td>4427</td>\n",
              "      <td>IAH</td>\n",
              "      <td>ATL</td>\n",
              "      <td>1125</td>\n",
              "      <td>119.0</td>\n",
              "      <td>689</td>\n",
              "      <td>1424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288445</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>DL</td>\n",
              "      <td>1112</td>\n",
              "      <td>MCO</td>\n",
              "      <td>ATL</td>\n",
              "      <td>2030</td>\n",
              "      <td>87.0</td>\n",
              "      <td>404</td>\n",
              "      <td>2157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298874</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>WN</td>\n",
              "      <td>4858</td>\n",
              "      <td>ALB</td>\n",
              "      <td>MCO</td>\n",
              "      <td>1505</td>\n",
              "      <td>195.0</td>\n",
              "      <td>1073</td>\n",
              "      <td>1820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        YEAR  MONTH  DAY  ...  SCHEDULED_TIME DISTANCE  SCHEDULED_ARRIVAL\n",
              "645400  2015      2   12  ...           330.0     2603               2230\n",
              "546962  2015      2    6  ...           227.0     1532               1212\n",
              "159193  2015      1   11  ...           119.0      689               1424\n",
              "288445  2015      1   19  ...            87.0      404               2157\n",
              "298874  2015      1   20  ...           195.0     1073               1820\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06IReH3NbH0C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "6d04852f-e371-47f6-f6d4-91bdab6d30bd"
      },
      "source": [
        "# Apply label encoder to each column with categorical data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in good_label_cols:\n",
        "    label_X_train[col] = label_encoder.fit_transform(X_train_full[col])\n",
        "    label_X_valid[col] = label_encoder.transform(X_valid_full[col])\n",
        "    label_X_test[col] = label_encoder.transform(X_test_full[col])\n",
        "\n",
        "label_X_train.head(10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>FLIGHT_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>645400</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>26</td>\n",
              "      <td>137</td>\n",
              "      <td>230</td>\n",
              "      <td>1500</td>\n",
              "      <td>330.0</td>\n",
              "      <td>2603</td>\n",
              "      <td>2230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546962</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1864</td>\n",
              "      <td>262</td>\n",
              "      <td>211</td>\n",
              "      <td>625</td>\n",
              "      <td>227.0</td>\n",
              "      <td>1532</td>\n",
              "      <td>1212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159193</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4427</td>\n",
              "      <td>146</td>\n",
              "      <td>18</td>\n",
              "      <td>1125</td>\n",
              "      <td>119.0</td>\n",
              "      <td>689</td>\n",
              "      <td>1424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288445</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1112</td>\n",
              "      <td>188</td>\n",
              "      <td>18</td>\n",
              "      <td>2030</td>\n",
              "      <td>87.0</td>\n",
              "      <td>404</td>\n",
              "      <td>2157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298874</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>4858</td>\n",
              "      <td>12</td>\n",
              "      <td>188</td>\n",
              "      <td>1505</td>\n",
              "      <td>195.0</td>\n",
              "      <td>1073</td>\n",
              "      <td>1820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460756</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>615</td>\n",
              "      <td>188</td>\n",
              "      <td>79</td>\n",
              "      <td>855</td>\n",
              "      <td>180.0</td>\n",
              "      <td>973</td>\n",
              "      <td>1055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783876</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>2663</td>\n",
              "      <td>169</td>\n",
              "      <td>97</td>\n",
              "      <td>1330</td>\n",
              "      <td>95.0</td>\n",
              "      <td>583</td>\n",
              "      <td>1605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72002</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>312</td>\n",
              "      <td>188</td>\n",
              "      <td>7</td>\n",
              "      <td>1438</td>\n",
              "      <td>127.0</td>\n",
              "      <td>852</td>\n",
              "      <td>1645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709158</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>271</td>\n",
              "      <td>111</td>\n",
              "      <td>49</td>\n",
              "      <td>1855</td>\n",
              "      <td>150.0</td>\n",
              "      <td>925</td>\n",
              "      <td>2125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120068</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>4592</td>\n",
              "      <td>280</td>\n",
              "      <td>130</td>\n",
              "      <td>1530</td>\n",
              "      <td>99.0</td>\n",
              "      <td>463</td>\n",
              "      <td>1709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        YEAR  MONTH  DAY  ...  SCHEDULED_TIME  DISTANCE  SCHEDULED_ARRIVAL\n",
              "645400  2015      2   12  ...           330.0      2603               2230\n",
              "546962  2015      2    6  ...           227.0      1532               1212\n",
              "159193  2015      1   11  ...           119.0       689               1424\n",
              "288445  2015      1   19  ...            87.0       404               2157\n",
              "298874  2015      1   20  ...           195.0      1073               1820\n",
              "460756  2015      1   31  ...           180.0       973               1055\n",
              "783876  2015      2   21  ...            95.0       583               1605\n",
              "72002   2015      1    5  ...           127.0       852               1645\n",
              "709158  2015      2   16  ...           150.0       925               2125\n",
              "120068  2015      1    8  ...            99.0       463               1709\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muODOQKC5ddx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4135e208-312a-47d6-9dee-cb6d274dd58d"
      },
      "source": [
        "# print validation test set\n",
        "label_X_valid.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>FLIGHT_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49651</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>297</td>\n",
              "      <td>20</td>\n",
              "      <td>97</td>\n",
              "      <td>855</td>\n",
              "      <td>100.0</td>\n",
              "      <td>528</td>\n",
              "      <td>935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252341</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1772</td>\n",
              "      <td>18</td>\n",
              "      <td>233</td>\n",
              "      <td>1103</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1587</td>\n",
              "      <td>1325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231406</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>782</td>\n",
              "      <td>171</td>\n",
              "      <td>232</td>\n",
              "      <td>2215</td>\n",
              "      <td>293.0</td>\n",
              "      <td>2402</td>\n",
              "      <td>608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601178</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>201</td>\n",
              "      <td>277</td>\n",
              "      <td>271</td>\n",
              "      <td>1730</td>\n",
              "      <td>122.0</td>\n",
              "      <td>697</td>\n",
              "      <td>1932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688416</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>490</td>\n",
              "      <td>161</td>\n",
              "      <td>212</td>\n",
              "      <td>1359</td>\n",
              "      <td>223.0</td>\n",
              "      <td>1182</td>\n",
              "      <td>1642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        YEAR  MONTH  DAY  ...  SCHEDULED_TIME  DISTANCE  SCHEDULED_ARRIVAL\n",
              "49651   2015      1    4  ...           100.0       528                935\n",
              "252341  2015      1   17  ...           262.0      1587               1325\n",
              "231406  2015      1   15  ...           293.0      2402                608\n",
              "601178  2015      2    9  ...           122.0       697               1932\n",
              "688416  2015      2   15  ...           223.0      1182               1642\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV6z8dmb5sfS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "7820673b-5189-41d2-cb32-b21eb376beaf"
      },
      "source": [
        "# print test set\n",
        "label_X_test.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>FLIGHT_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>SCHEDULED_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>SCHEDULED_ARRIVAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>1046</td>\n",
              "      <td>169</td>\n",
              "      <td>233</td>\n",
              "      <td>700</td>\n",
              "      <td>65</td>\n",
              "      <td>255</td>\n",
              "      <td>905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>2251</td>\n",
              "      <td>169</td>\n",
              "      <td>255</td>\n",
              "      <td>700</td>\n",
              "      <td>80</td>\n",
              "      <td>345</td>\n",
              "      <td>820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>857</td>\n",
              "      <td>169</td>\n",
              "      <td>281</td>\n",
              "      <td>700</td>\n",
              "      <td>90</td>\n",
              "      <td>397</td>\n",
              "      <td>830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>2864</td>\n",
              "      <td>171</td>\n",
              "      <td>49</td>\n",
              "      <td>700</td>\n",
              "      <td>295</td>\n",
              "      <td>2329</td>\n",
              "      <td>1455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>3220</td>\n",
              "      <td>171</td>\n",
              "      <td>233</td>\n",
              "      <td>700</td>\n",
              "      <td>80</td>\n",
              "      <td>370</td>\n",
              "      <td>920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH  DAY  ...  SCHEDULED_TIME  DISTANCE  SCHEDULED_ARRIVAL\n",
              "0  2015      2   25  ...              65       255                905\n",
              "1  2015      2   25  ...              80       345                820\n",
              "2  2015      2   25  ...              90       397                830\n",
              "3  2015      2   25  ...             295      2329               1455\n",
              "4  2015      2   25  ...              80       370                920\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4576ya_MO2nU"
      },
      "source": [
        "# Select numerical columns\n",
        "numerical_cols = [cname for cname in label_X_train.columns if\n",
        "                label_X_train[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Keep selected columns only\n",
        "categorical_cols = good_label_cols\n",
        "my_cols = categorical_cols + numerical_cols  # sometime use category_cols instead of good_label_cols for one-hot encoding\n",
        "X_train = label_X_train[my_cols].copy()\n",
        "X_valid = label_X_valid[my_cols].copy()\n",
        "X_test = label_X_test[my_cols].copy()\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wvUzgLvyE7N"
      },
      "source": [
        "### Model using Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1eDbCsWDpbQ"
      },
      "source": [
        "# Define Preprocessing Steps and import dependecies\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "#numerical_transformer = SimpleImputer(strategy='mean')\n",
        "#numerical_transformer = KNNImputer(n_neighbors=3)\n",
        "numerical_transformer = Pipeline(steps=[('imputer',SimpleImputer() ),('scaler', StandardScaler())])\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])\n",
        "#categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder())])\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRCxkZoUyJTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d7aa94-aa9d-453c-f20c-6f0ae0cee8a2"
      },
      "source": [
        "# import required libraries\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, roc_auc_score\n",
        "\n",
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "# Step 2: Define the Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_1 = LogisticRegression()\n",
        "\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model_1)])\n",
        "my_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = accuracy_score(y_valid, preds)\n",
        "avg_precisionScore = average_precision_score(y_valid, preds)\n",
        "\n",
        "print(\"Pipeline score is\", my_pipeline.score)\n",
        "print('Accuracy Score:', score)    # Not a good metrics for imbalanced dataset\n",
        "print('Average Precision Score:', avg_precisionScore)\n",
        "print(\"The roc_auc_score is :\", roc_auc_score(y_valid, preds))\n",
        "print(\"The  f1_score is :\", f1_score(y_valid, preds, average= 'macro'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline score is <function Pipeline.score at 0x7fa82ff73e18>\n",
            "Accuracy Score: 0.9658286245619054\n",
            "Average Precision Score: 0.03417137543809456\n",
            "The roc_auc_score is : 0.5\n",
            "The  f1_score is : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt14JiwX6sZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ce66d2-f61d-4caf-f4f3-c65247dbbb76"
      },
      "source": [
        "# print classification report (confusion matrix)\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print (classification_report(y_valid, preds))\n",
        "print(confusion_matrix(y_valid,preds))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98    162039\n",
            "           1       0.00      0.00      0.00      5733\n",
            "\n",
            "    accuracy                           0.97    167772\n",
            "   macro avg       0.48      0.50      0.49    167772\n",
            "weighted avg       0.93      0.97      0.95    167772\n",
            "\n",
            "[[162039      0]\n",
            " [  5733      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4El5WkcEzkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da97081-1a2b-49bb-c89d-157f84317b5a"
      },
      "source": [
        "# Cross validation Score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(my_pipeline, X_train, y_train, cv=3)\n",
        "\n",
        "# Print the mean score and 95% confidence interval\n",
        "print(\"Accuracy: %0.2f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.97 (+/- 0.00000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtGPOHnXEIU4"
      },
      "source": [
        "## Hyperparameter Tuning with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYC2SsDxHmN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8fb612-8e73-4fc0-d51a-bea3a2c4e733"
      },
      "source": [
        "# import required libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score\n",
        "\n",
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "# Step 2: Define the Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "\n",
        "cv=KFold(n_splits=5,random_state=None,shuffle=False)\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('clf', clf)])\n",
        "grid={'clf__penalty': ['l1', 'l2']}\n",
        "parameters1 = { 'clf__C': [0.001, 0.01, 0.1,1,10],'clf__penalty': ['l1', 'l2'], 'clf__solver':['l1', 'l2', 'elasticnet', 'none']}\n",
        "Grid1 = GridSearchCV(my_pipeline, grid, cv = cv, scoring = 'f1_macro')\n",
        "\n",
        "Grid1.fit(X_train, y_train)\n",
        "\n",
        "#Get the best estimator and print out the estimator model\n",
        "best_clf = Grid1.best_estimator_\n",
        "print (best_clf)\n",
        "\n",
        "#Use best estimator to make predictions on the test set\n",
        "y_pred = best_clf.predict(X_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline(memory=None,\n",
            "         steps=[('preprocessor',\n",
            "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
            "                                   sparse_threshold=0.3,\n",
            "                                   transformer_weights=None,\n",
            "                                   transformers=[('num',\n",
            "                                                  Pipeline(memory=None,\n",
            "                                                           steps=[('imputer',\n",
            "                                                                   SimpleImputer(add_indicator=False,\n",
            "                                                                                 copy=True,\n",
            "                                                                                 fill_value=None,\n",
            "                                                                                 missing_values=nan,\n",
            "                                                                                 strategy='mean',\n",
            "                                                                                 verbose=0)),\n",
            "                                                                  ('scaler',\n",
            "                                                                   StandardScaler(copy=True,\n",
            "                                                                                  with_mean=T...\n",
            "                                                                                 verbose=0))],\n",
            "                                                           verbose=False),\n",
            "                                                  ['AIRLINE', 'ORIGIN_AIRPORT',\n",
            "                                                   'DESTINATION_AIRPORT'])],\n",
            "                                   verbose=False)),\n",
            "                ('clf',\n",
            "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
            "                                    fit_intercept=True, intercept_scaling=1,\n",
            "                                    l1_ratio=None, max_iter=100,\n",
            "                                    multi_class='auto', n_jobs=None,\n",
            "                                    penalty='l2', random_state=None,\n",
            "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                                    warm_start=False))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkWbEMagFCvM"
      },
      "source": [
        "# Preprocessing of test data, fit model\n",
        "preds_test = best_clf.predict(X_test)\n",
        "\n",
        "# Save test predictions to file\n",
        "output = pd.DataFrame({'Id': X_test.index,'CANCELLED': preds_test})\n",
        "output.to_csv('submission_LR.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sufb0JL5sYDe"
      },
      "source": [
        "### Model using Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LLDyhG1Dv8F"
      },
      "source": [
        "# Define Preprocessing Steps and import dependecies\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = KNNImputer(n_neighbors=3)\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Nl-6S8RlwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "483ccd5f-7e85-4097-c090-a1d90855a5e3"
      },
      "source": [
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "# Step 2: Define the Model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model_1 = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# Step 3: Create and Evaluate the Pipeline\n",
        "from sklearn.metrics import accuracy_score,average_precision_score,f1_score,roc_auc_score\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model_1)])\n",
        "my_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = accuracy_score(y_valid, preds)\n",
        "avg_precisionScore = average_precision_score(y_valid, preds)\n",
        "\n",
        "print('Accuracy Score:', score)\n",
        "print('Average Precision Score:', avg_precisionScore)\n",
        "print(\"The macro averaged f1_score is :\", f1_score(y_valid, preds, average='macro'))\n",
        "print(\"The mairo averaged f1_score is :\", f1_score(y_valid, preds, average='micro'))\n",
        "print(\"The weighted averaged f1_score is :\", f1_score(y_valid, preds, average='weighted'))\n",
        "print(\"The  f1_score is :\", f1_score(y_valid, preds, average='macro'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7f8990ed70eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Bundle preprocessing and modeling code in a pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmy_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmy_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Preprocessing of validation data, get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCtNiLMskTTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454f8185-9493-4c19-d548-bb538f5f580b"
      },
      "source": [
        "# Cross validation Score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(my_pipeline, X_train, y_train, cv=3)\n",
        "\n",
        "# Print the mean score and 95% confidence interval\n",
        "print(\"Accuracy: %0.2f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.96 (+/- 0.00069)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1xMwAiOn1sF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c476876c-3a25-437e-d7f4-832c82b14e50"
      },
      "source": [
        "# print classification report (confusion matrix)\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print (classification_report(y_valid, preds))\n",
        "print (confusion_matrix(y_valid, preds))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    162039\n",
            "           1       0.41      0.44      0.42      5733\n",
            "\n",
            "    accuracy                           0.96    167772\n",
            "   macro avg       0.69      0.71      0.70    167772\n",
            "weighted avg       0.96      0.96      0.96    167772\n",
            "\n",
            "[[158411   3628]\n",
            " [  3232   2501]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp8X4bygpc-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59095637-f33c-471b-a070-acd0f5682a9c"
      },
      "source": [
        "# Use imbalance library to calculate sensitiivty score  of model\n",
        "from imblearn.metrics import sensitivity_score\n",
        "print(sensitivity_score(y_valid, preds, average='macro'))\n",
        "print(sensitivity_score(y_valid, preds, average='micro'))\n",
        "print(sensitivity_score(y_valid, preds, average='weighted'))\n",
        "print(sensitivity_score(y_valid, preds, average=None))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7069283108834434\n",
            "0.9591111746894595\n",
            "0.9591111746894595\n",
            "[0.97761033 0.43624629]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwq3Cw27qiHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08725262-c7ff-4159-db70-df94f151c311"
      },
      "source": [
        "# Use imbalance library to calculate specificity score  of model\n",
        "from imblearn.metrics import specificity_score\n",
        "print(specificity_score(y_valid, preds, average='macro'))\n",
        "print(specificity_score(y_valid, preds, average='micro'))\n",
        "print(specificity_score(y_valid, preds, average='weighted'))\n",
        "print(specificity_score(y_valid, preds, average=None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7069283108834434\n",
            "0.9591111746894595\n",
            "0.45474544707742726\n",
            "[0.43624629 0.97761033]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WupO8eGFUfkd"
      },
      "source": [
        "# Preprocessing of test data, fit model\n",
        "preds_test = my_pipeline.predict(X_test)\n",
        "\n",
        "# Save test predictions to file\n",
        "output = pd.DataFrame({'Id': X_test.index,'CANCELLED': preds_test})\n",
        "output.to_csv('submission_DT.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOB8JJhXsK5C"
      },
      "source": [
        "### Model using Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIVwvzjTDyFp"
      },
      "source": [
        "# Define Preprocessing Steps and import dependecies\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT3Z3nqtsQAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f67f159-3cd0-4c4c-cf55-0755d6133831"
      },
      "source": [
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "# Step 2: Define the Model\n",
        "class_weight=dict({0:1,1:40})\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_2 = RandomForestClassifier(n_estimators=100, random_state=0,class_weight=class_weight )\n",
        "\n",
        "# Step 3: Create and Evaluate the Pipeline\n",
        "from sklearn.metrics import accuracy_score,average_precision_score,roc_auc_score\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model_2)])\n",
        "\n",
        "# Preprocessing of training data, fit model\n",
        "my_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = accuracy_score(y_valid, preds)\n",
        "avg_precisionScore = average_precision_score(y_valid, preds)\n",
        "\n",
        "print('Accuracy Score:', score)\n",
        "print('Average Precision Score:', avg_precisionScore)\n",
        "print(\"The roc_auc_score is :\", roc_auc_score(y_valid, preds, average='macro'))\n",
        "print(\"The weighted averaged f1_score is :\", f1_score(y_valid, preds, average='weighted'))\n",
        "print(\"The  f1_score is :\", f1_score(y_valid, preds, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.9742507689006509\n",
            "Average Precision Score: 0.2790498754956142\n",
            "The macro averaged f1_score is : 0.7160599627544343\n",
            "The mairo averaged f1_score is : 0.9742507689006509\n",
            "The weighted averaged f1_score is : 0.9683150141688915\n",
            "The  f1_score is : 0.7160599627544343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V6YHFh7s4zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d14e46f-5601-457f-c150-e74904cef24d"
      },
      "source": [
        "# Cross validation Score\n",
        "scores = cross_val_score(my_pipeline, X_train, y_train, cv=3)\n",
        "\n",
        "# Print the mean score and 95% confidence interval\n",
        "print(\"Accuracy: %0.2f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.97 (+/- 0.00063)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vixznA5ytCDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966603b5-5dcf-4dcf-c578-67f319878364"
      },
      "source": [
        "# print classification report (confusion matrix)\n",
        "from sklearn.metrics import classification_report\n",
        "print (classification_report(y_valid, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    162039\n",
            "           1       0.84      0.30      0.45      5733\n",
            "\n",
            "    accuracy                           0.97    167772\n",
            "   macro avg       0.91      0.65      0.72    167772\n",
            "weighted avg       0.97      0.97      0.97    167772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r-C931otJ9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ac7f9f-f27b-4b80-ad2b-172d2e2c3675"
      },
      "source": [
        "# Use imbalance library to calculate sensitiivty score  of model\n",
        "from imblearn.metrics import sensitivity_score\n",
        "print(sensitivity_score(y_valid, preds, average='macro'))\n",
        "print(sensitivity_score(y_valid, preds, average='micro'))\n",
        "print(sensitivity_score(y_valid, preds, average='weighted'))\n",
        "print(sensitivity_score(y_valid, preds, average=None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6502392203718075\n",
            "0.9742507689006509\n",
            "0.9742507689006509\n",
            "[0.998019   0.30245945]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fidLdTeItKxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6070c60-c9dd-42a7-f620-8cc851091e50"
      },
      "source": [
        "# Use imbalance library to calculate specificity score  of model\n",
        "from imblearn.metrics import specificity_score\n",
        "print(specificity_score(y_valid, preds, average='macro'))\n",
        "print(specificity_score(y_valid, preds, average='micro'))\n",
        "print(specificity_score(y_valid, preds, average='weighted'))\n",
        "print(specificity_score(y_valid, preds, average=None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6502392203718075\n",
            "0.9742507689006509\n",
            "0.32622767184296414\n",
            "[0.30245945 0.998019  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBL5cybwtQ7n"
      },
      "source": [
        "# Preprocessing of test data, fit model\n",
        "preds_test = my_pipeline.predict(X_test)\n",
        "\n",
        "# Save test predictions to file\n",
        "output = pd.DataFrame({'Id': X_test.index,'CANCELLED': preds_test})\n",
        "output.to_csv('submission_RF.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKslXORZ5ku_"
      },
      "source": [
        "### Model using Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI1QOZcLD1SH"
      },
      "source": [
        "# Define Preprocessing Steps and import dependecies\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = Pipeline(steps=[('imputer',SimpleImputer() ),('scaler', StandardScaler())])\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FmkhQXN5rYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0edff5-247a-4036-f6b9-81d8e54b218d"
      },
      "source": [
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "numerical_transformer = Pipeline(steps=[('imputer',SimpleImputer() ),('scaler', StandardScaler())])\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "# Step 2: Define the Model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model_3 = GaussianNB()\n",
        "\n",
        "\n",
        "# Step 3: Create and Evaluate the Pipeline\n",
        "from sklearn.metrics import accuracy_score,average_precision_score\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model_3)])\n",
        "\n",
        "# Preprocessing of training data, fit model\n",
        "my_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = accuracy_score(y_valid, preds)\n",
        "avg_precisionScore = average_precision_score(y_valid, preds)\n",
        "\n",
        "print('Accuracy Score:', score)\n",
        "print('Average Precision Score:', avg_precisionScore)\n",
        "print(\"The macro averaged f1_score is :\", f1_score(y_valid, preds, average='macro'))\n",
        "print(\"The mairo averaged f1_score is :\", f1_score(y_valid, preds, average='micro'))\n",
        "print(\"The weighted averaged f1_score is :\", f1_score(y_valid, preds, average='weighted'))\n",
        "print(\"The  f1_score is :\", f1_score(y_valid, preds, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.9658286245619054\n",
            "Average Precision Score: 0.03417137543809456\n",
            "The macro averaged f1_score is : 0.49130865859537737\n",
            "The mairo averaged f1_score is : 0.9658286245619054\n",
            "The weighted averaged f1_score is : 0.9490399319330562\n",
            "The  f1_score is : 0.49130865859537737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIe8kVwG6D3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a60d67-1167-4f38-ac4f-dda267f5a2a0"
      },
      "source": [
        "# Cross validation Score\n",
        "scores = cross_val_score(my_pipeline, X_train, y_train, cv=5)\n",
        "# Print the mean score and 95% confidence interval\n",
        "print(\"Accuracy: %0.2f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.97 (+/- 0.00001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4-gUA8W6ES9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1b64ba-1cc8-4a61-dda7-99e14e46a7be"
      },
      "source": [
        "# print classification report (confusion matrix)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print (classification_report(y_valid, preds))\n",
        "print (confusion_matrix(y_valid, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98    162039\n",
            "           1       0.00      0.00      0.00      5733\n",
            "\n",
            "    accuracy                           0.97    167772\n",
            "   macro avg       0.48      0.50      0.49    167772\n",
            "weighted avg       0.93      0.97      0.95    167772\n",
            "\n",
            "[[162039      0]\n",
            " [  5733      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drr6ryo46EgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915df675-353a-4cf1-8017-94094f8dbce0"
      },
      "source": [
        "# Use imbalance library to calculate sensitiivty score  of model\n",
        "from imblearn.metrics import sensitivity_score\n",
        "print(sensitivity_score(y_valid, preds, average='macro'))\n",
        "print(sensitivity_score(y_valid, preds, average='micro'))\n",
        "print(sensitivity_score(y_valid, preds, average='weighted'))\n",
        "print(sensitivity_score(y_valid, preds, average=None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "0.9658286245619054\n",
            "0.9658286245619054\n",
            "[1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDypGbzx6RDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5ea52c-2946-4062-d600-2eb240f7b705"
      },
      "source": [
        "# Use imbalance library to calculate specificity score  of model\n",
        "from imblearn.metrics import specificity_score\n",
        "print(specificity_score(y_valid, preds, average='macro'))\n",
        "print(specificity_score(y_valid, preds, average='micro'))\n",
        "print(specificity_score(y_valid, preds, average='weighted'))\n",
        "print(specificity_score(y_valid, preds, average=None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "0.9658286245619054\n",
            "0.03417137543809456\n",
            "[0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alQ3OUBV6VC0"
      },
      "source": [
        "# Preprocessing of test data, fit model\n",
        "preds_test = my_pipeline.predict(X_test)\n",
        "\n",
        "# Save test predictions to file\n",
        "output = pd.DataFrame({'Id': X_test.index,'CANCELLED': preds_test})\n",
        "output.to_csv('submission_NB.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dChkfH6X3esy"
      },
      "source": [
        "## Approach 2 : Under Sampling with RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNjyaZgiD3LM"
      },
      "source": [
        "# Define Preprocessing Steps and import dependecies\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR5ikSRO8ATn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f99aee-bed5-4ca1-fa09-6ad5fb8fe834"
      },
      "source": [
        "# import required libraries\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score\n",
        "\n",
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "# Step 2: Perform Undersampling\n",
        "ns_model = NearMiss()\n",
        "\n",
        "# Step 2: Define the Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_4 = RandomForestClassifier(random_state = 2)\n",
        "\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline2 = Pipeline(steps=[('preprocessor', preprocessor), ('ns_model', ns_model), ('model_4',model_4)])\n",
        "my_pipeline2.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline2.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = accuracy_score(y_valid, preds)\n",
        "avg_precisionScore = average_precision_score(y_valid, preds)\n",
        "\n",
        "print(\"Pipeline score is\", my_pipeline2.score)\n",
        "print('Accuracy Score:', score)\n",
        "print('Average Precision Score:', avg_precisionScore)\n",
        "print(\"The macro averaged f1_score is :\", f1_score(y_valid, preds, average='macro'))\n",
        "print(\"The mairo averaged f1_score is :\", f1_score(y_valid, preds, average='micro'))\n",
        "print(\"The weighted averaged f1_score is :\", f1_score(y_valid, preds, average='weighted'))\n",
        "print(\"The  f1_score is :\", f1_score(y_valid, preds, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline score is <function Pipeline.score at 0x7f2c10033268>\n",
            "Accuracy Score: 0.3310206709105214\n",
            "Average Precision Score: 0.041375559918451245\n",
            "The macro averaged f1_score is : 0.27756244278033115\n",
            "The mairo averaged f1_score is : 0.3310206709105214\n",
            "The weighted averaged f1_score is : 0.4606520130094718\n",
            "The  f1_score is : 0.27756244278033115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHMoldVZ8Nbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b71b0d5-bd8e-4488-b766-7c8841d66353"
      },
      "source": [
        "# print classification report (confusion matrix)\n",
        "from sklearn.metrics import classification_report\n",
        "print (classification_report(y_valid, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.31      0.47    162039\n",
            "           1       0.04      0.86      0.08      5733\n",
            "\n",
            "    accuracy                           0.33    167772\n",
            "   macro avg       0.51      0.59      0.28    167772\n",
            "weighted avg       0.95      0.33      0.46    167772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qOaznNkTQ_y"
      },
      "source": [
        "## Approach 3 : Over Sampling with RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1bAyky6TUL4"
      },
      "source": [
        "# Define Preprocessing Steps and import dependecies\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU4S6-2qTeIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ef5f14-94d2-42b3-8be2-6ad1dd8932d1"
      },
      "source": [
        "# import useful libraries\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# print the classes in target variable\n",
        "print(Counter(y_train))\n",
        "\n",
        "# Perform under sampling\n",
        "os = RandomOverSampler(0.5)\n",
        "#X_train_ns,y_train_ns= os.fit_sample(X_train,y_train)\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 648137, 1: 22949})\n",
            "The number of classes before fit Counter({0: 648137, 1: 22949})\n",
            "The number of classes after fit Counter({0.0: 448423, 1.0: 334855})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URrDI7W3T7Ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34544c37-07a9-4036-8d01-f50ee8ff8cff"
      },
      "source": [
        "# import required libraries\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score\n",
        "\n",
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "# Step 2: Perform Undersampling\n",
        "os_model = RandomOverSampler(0.6)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_5 = RandomForestClassifier(random_state = 2)\n",
        "\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline3 = Pipeline(steps=[('preprocessor', preprocessor), ('os_model', os_model), ('model_1',model_5)])\n",
        "my_pipeline3.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline3.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = accuracy_score(y_valid, preds)\n",
        "avg_precisionScore = average_precision_score(y_valid, preds)\n",
        "\n",
        "print(\"Pipeline score is\", my_pipeline3.score)\n",
        "print('Accuracy Score:', score)\n",
        "print('Average Precision Score:', avg_precisionScore)\n",
        "print(\"The macro averaged f1_score is :\", f1_score(y_valid, preds, average='macro'))\n",
        "print(\"The mairo averaged f1_score is :\", f1_score(y_valid, preds, average='micro'))\n",
        "print(\"The weighted averaged f1_score is :\", f1_score(y_valid, preds, average='weighted'))\n",
        "print(\"The  f1_score is :\", f1_score(y_valid, preds, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline score is <function Pipeline.score at 0x7f2c106381e0>\n",
            "Accuracy Score: 0.97314212145054\n",
            "Average Precision Score: 0.2968245242069568\n",
            "The macro averaged f1_score is : 0.7478320051725064\n",
            "The mairo averaged f1_score is : 0.97314212145054\n",
            "The weighted averaged f1_score is : 0.9699028250112963\n",
            "The  f1_score is : 0.7478320051725064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAS_lFIEUIxR"
      },
      "source": [
        "# print classification report (confusion matrix)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print (classification_report(y_valid, preds))\n",
        "print (confusion_matrix(y_valid, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0XPxaGHWulm"
      },
      "source": [
        "## Approach 4 : SMOTETomek with RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teXEjxcUWyrQ"
      },
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "sm=SMOTETomek(0.75)\n",
        "X_train_ns,y_train_ns=sm.fit_sample(X_train,y_train)\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrLlGVHGZ3KN"
      },
      "source": [
        "# Define Preprocessing Steps and import dependecies\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y87AeKmnXmMw"
      },
      "source": [
        "# import required libraries\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score\n",
        "\n",
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "# Step 2: Perform Undersampling\n",
        "sm_model = SMOTETomek(0.5)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_6 = RandomForestClassifier(random_state = 2)\n",
        "\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline4 = Pipeline(steps=[('preprocessor', preprocessor), ('os_model', os_model), ('model_1',model_6)])\n",
        "my_pipeline4.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline4.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = accuracy_score(y_valid, preds)\n",
        "avg_precisionScore = average_precision_score(y_valid, preds)\n",
        "\n",
        "print(\"Pipeline score is\", my_pipeline4.score)\n",
        "print('Accuracy Score:', score)\n",
        "print('Average Precision Score:', avg_precisionScore)\n",
        "print(\"The macro averaged f1_score is :\", f1_score(y_valid, preds, average='macro'))\n",
        "print(\"The mairo averaged f1_score is :\", f1_score(y_valid, preds, average='micro'))\n",
        "print(\"The weighted averaged f1_score is :\", f1_score(y_valid, preds, average='weighted'))\n",
        "print(\"The  f1_score is :\", f1_score(y_valid, preds, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxYTAsY2YnSY"
      },
      "source": [
        "# print classification report (confusion matrix)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print (classification_report(y_valid, preds))\n",
        "print(confusion_matrix(y_valid, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0q_7jM-ZegO"
      },
      "source": [
        "## Approach 5 : Ensemble Techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AUw8el8ZoJh"
      },
      "source": [
        "# Define Preprocessing Steps and import dependecies\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "#numerical_transformer = SimpleImputer(strategy='mean')\n",
        "numerical_transformer = Pipeline(steps=[('imputer',SimpleImputer() ),('scaler', StandardScaler())])\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent'))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVbiegk7Z6oE"
      },
      "source": [
        "# import required libraries\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score\n",
        "\n",
        "# Step 1 : Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(transformers=[ ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n",
        "\n",
        "# Step 2: Define the Model\n",
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "model_7 = EasyEnsembleClassifier(n_estimators=100 )\n",
        "\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline5 = Pipeline(steps=[('preprocessor', preprocessor), ('model_7',model_7)])\n",
        "my_pipeline5.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline5.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = accuracy_score(y_valid, preds)\n",
        "avg_precisionScore = average_precision_score(y_valid, preds)\n",
        "\n",
        "print(\"Pipeline score is\", my_pipeline5.score)\n",
        "print('Accuracy Score:', score)\n",
        "print('Average Precision Score:', avg_precisionScore)\n",
        "print(\"The macro averaged f1_score is :\", f1_score(y_valid, preds, average='macro'))\n",
        "print(\"The mairo averaged f1_score is :\", f1_score(y_valid, preds, average='micro'))\n",
        "print(\"The weighted averaged f1_score is :\", f1_score(y_valid, preds, average='weighted'))\n",
        "print(\"The  f1_score is :\", f1_score(y_valid, preds, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtOr9w8WbBsV"
      },
      "source": [
        "# print classification report (confusion matrix)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print (classification_report(y_valid, preds))\n",
        "print(confusion_matrix(y_valid, preds))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}